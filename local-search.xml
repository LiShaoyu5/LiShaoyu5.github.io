<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[TF2]2. Tensor and Basic Modeling</title>
    <link href="/2020/2-TF2-Tensor-and-Basic-Modeling/"/>
    <url>/2020/2-TF2-Tensor-and-Basic-Modeling/</url>
    
    <content type="html"><![CDATA[<div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tfprint(tf.__version__)</code></pre></div><div class="hljs"><pre><code class="hljs angelscript"><span class="hljs-number">2.1</span><span class="hljs-number">.0</span></code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># print(tf.test.is_gpu_available())  # True, but not recommended, use following instead</span>print(tf.config.list_physical_devices(<span class="hljs-string">'GPU'</span>))</code></pre></div><div class="hljs"><pre><code class="hljs scheme">[<span class="hljs-name">PhysicalDevice</span>(<span class="hljs-name">name=</span><span class="hljs-symbol">'/physical_device:GPU:0</span>', device_type=<span class="hljs-symbol">'GPU</span>')]</code></pre></div><h1 id="1-张量与操作"><a href="#1-张量与操作" class="headerlink" title="1. 张量与操作"></a>1. 张量与操作</h1><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># different shape and rank of tensor</span><span class="hljs-comment"># rank 0</span>r0 = tf.Variable(<span class="hljs-string">'rank0'</span>, tf.string)print(r0, <span class="hljs-string">'\nrank: '</span>, tf.rank(r0), <span class="hljs-string">'  shape: '</span>, tf.shape(r0), <span class="hljs-string">'\n'</span>)<span class="hljs-comment"># rank 1</span>r1 = tf.Variable([<span class="hljs-string">'rank1'</span>], tf.string)print(r1, <span class="hljs-string">'\nrank: '</span>, tf.rank(r1), <span class="hljs-string">'  shape: '</span>, tf.shape(r1), <span class="hljs-string">'\n'</span>)<span class="hljs-comment"># rank 2</span>r2 = tf.Variable([[<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]], tf.int16)print(r2, <span class="hljs-string">'\nrank: '</span>, tf.rank(r2), <span class="hljs-string">'  shape: '</span>, tf.shape(r2), <span class="hljs-string">'\n'</span>)</code></pre></div><div class="hljs"><pre><code class="hljs routeros">&lt;tf.Variable <span class="hljs-string">'Variable:0'</span> shape=() <span class="hljs-attribute">dtype</span>=string, <span class="hljs-attribute">numpy</span>=b'rank0'&gt;rank:  tf.Tensor(0, shape=(), <span class="hljs-attribute">dtype</span>=int32)   shape:  tf.Tensor([], shape=(0,), <span class="hljs-attribute">dtype</span>=int32)&lt;tf.Variable <span class="hljs-string">'Variable:0'</span> shape=(1,) <span class="hljs-attribute">dtype</span>=string, <span class="hljs-attribute">numpy</span>=array([b<span class="hljs-string">'rank1'</span>], <span class="hljs-attribute">dtype</span>=object)&gt;rank:  tf.Tensor(1, shape=(), <span class="hljs-attribute">dtype</span>=int32)   shape:  tf.Tensor([1], shape=(1,), <span class="hljs-attribute">dtype</span>=int32)&lt;tf.Variable <span class="hljs-string">'Variable:0'</span> shape=(2, 1) <span class="hljs-attribute">dtype</span>=int32, numpy=array([[1],       [2]])&gt;rank:  tf.Tensor(2, shape=(), <span class="hljs-attribute">dtype</span>=int32)   shape:  tf.Tensor([2 1], shape=(2,), <span class="hljs-attribute">dtype</span>=int32)</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># create tensor</span>print(tf.constant([[<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>], [<span class="hljs-number">3</span>]], tf.int16))print(tf.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), tf.float16))<span class="hljs-comment"># print(tf.dtypes.cast(x, tf.int16))</span></code></pre></div><div class="hljs"><pre><code class="hljs angelscript">tf.Tensor([[<span class="hljs-number">1</span>] [<span class="hljs-number">2</span>] [<span class="hljs-number">3</span>]], shape=(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>), dtype=<span class="hljs-built_in">int</span>16)tf.Tensor([[<span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span>] [<span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span>] [<span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span>]], shape=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), dtype=<span class="hljs-built_in">float</span>16)</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># reshape</span>t = tf.ones((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), tf.int16)print(tf.reshape(t, (<span class="hljs-number">3</span>, <span class="hljs-number">2</span>)))</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">tf.Tensor([[<span class="hljs-number">1</span> <span class="hljs-number">1</span>] [<span class="hljs-number">1</span> <span class="hljs-number">1</span>] [<span class="hljs-number">1</span> <span class="hljs-number">1</span>]], shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-built_in">int</span>16)</code></pre></div><p>Numpy与TensorFlow的一些函数对比:</p><div class="table-container"><table><thead><tr><th style="text-align:left">Numpy</th><th style="text-align:left">TensorFlow</th></tr></thead><tbody><tr><td style="text-align:left">a = np.zeros((2, 3))</td><td style="text-align:left">b = tf.zeros((2, 3))</td></tr><tr><td style="text-align:left">np.sum(a, axis=1)</td><td style="text-align:left">b = tf.reduce_sum(b, axis=1)</td></tr><tr><td style="text-align:left">a.shape</td><td style="text-align:left">b.get_shape()</td></tr><tr><td style="text-align:left">np.reshape(a, (3, 2))</td><td style="text-align:left">tf.reshape(b, (3, 2))</td></tr><tr><td style="text-align:left">a * 5 + 1</td><td style="text-align:left">b * 5 + 1</td></tr><tr><td style="text-align:left">np.dot(a, x)</td><td style="text-align:left">tf.matmul(b, x)</td></tr><tr><td style="text-align:left">a[0, 0]; a[:, 0]; a[0, :]</td><td style="text-align:left">b[0, 0]; b[:, 0]; b[0, :]</td></tr></tbody></table></div><p>常用的一些tensor操作包：</p><ul><li>tf.strings</li><li>tf.debugging</li><li>tf.dtypes</li><li>tf.math</li><li>tf.random</li><li>tf.feature_column</li></ul><h1 id="2-常用层"><a href="#2-常用层" class="headerlink" title="2. 常用层"></a>2. 常用层</h1><ul><li>tf.keras.layers： 基于tf.nn高度封装的各种层</li><li>tf.nn：底层的函数库</li></ul><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 数据</span>a = tf.random.uniform((<span class="hljs-number">10</span>, <span class="hljs-number">100</span>, <span class="hljs-number">50</span>), minval=<span class="hljs-number">-0.5</span>, maxval=<span class="hljs-number">0.5</span>)<span class="hljs-comment"># 常用层有Dense，Conv2D，LSTM，BatchNormalization，Dropout等</span>x = tf.keras.layers.LSTM(<span class="hljs-number">100</span>)(a)<span class="hljs-comment"># 在层中添加激活函数</span>tf.keras.layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)tf.keras.layers.Dense(<span class="hljs-number">64</span>, activation=tf.nn.relu)<span class="hljs-comment"># L1正则化应用于内核矩阵</span>tf.keras.layers.Dense(<span class="hljs-number">64</span>, kernel_regularizer=tf.keras.regularizers.l1(<span class="hljs-number">0.01</span>))<span class="hljs-comment"># L2正则化应用于偏差函数</span>tf.keras.layers.Dense(<span class="hljs-number">64</span>, bias_regularizer=tf.keras.regularizers.l2(<span class="hljs-number">0.01</span>))<span class="hljs-comment"># 内核初始化为随机正交矩阵</span>tf.keras.layers.Dense(<span class="hljs-number">64</span>, kernel_initializer=<span class="hljs-string">'orthogonal'</span>)<span class="hljs-comment"># 偏差向量初始化为2.0</span>tf.keras.layers.Dense(<span class="hljs-number">64</span>, bias_initializer=tf.keras.initializers.Constant(<span class="hljs-number">2.0</span>))</code></pre></div><h1 id="3-三种建模方式"><a href="#3-三种建模方式" class="headerlink" title="3. 三种建模方式"></a>3. 三种建模方式</h1><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre></div><h2 id="1-Sequential-Model-顺序模型"><a href="#1-Sequential-Model-顺序模型" class="headerlink" title="(1) Sequential Model (顺序模型)"></a>(1) Sequential Model (顺序模型)</h2><p>tf.keras.Sequential</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 第一种Sequential Modeling</span>model = tf.keras.Sequential()model.add(layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>))model.add(layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>))model.add(layers.Dense(<span class="hljs-number">10</span>))</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 第二种Sequential Modeling</span>model = tf.keras.Sequential([    layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">32</span>,)),    layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>),    layers.Dense(<span class="hljs-number">10</span>)])</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 配置模型训练用的参数</span>model.compile(    optimizer=tf.keras.optimizers.Adam(<span class="hljs-number">0.01</span>),    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),    metrics=[<span class="hljs-string">'accuracy'</span>])</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 训练</span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npdata = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">32</span>))labels = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">10</span>))model.fit(data, labels, epochs=<span class="hljs-number">10</span>, batch_size=<span class="hljs-number">10</span>)</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">Train on <span class="hljs-number">1000</span> samplesEpoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">470</span>us/sample - loss: <span class="hljs-number">502.7293</span> - accuracy: <span class="hljs-number">0.1010</span>Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">102</span>us/sample - loss: <span class="hljs-number">5018.7255</span> - accuracy: <span class="hljs-number">0.0930</span>Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">104</span>us/sample - loss: <span class="hljs-number">18110.6599</span> - accuracy: <span class="hljs-number">0.0970</span>Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">107</span>us/sample - loss: <span class="hljs-number">38622.3230</span> - accuracy: <span class="hljs-number">0.1150</span>Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">107</span>us/sample - loss: <span class="hljs-number">63793.2827</span> - accuracy: <span class="hljs-number">0.1200</span>Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">107</span>us/sample - loss: <span class="hljs-number">101561.8852</span> - accuracy: <span class="hljs-number">0.0880</span>Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">107</span>us/sample - loss: <span class="hljs-number">131743.5854</span> - accuracy: <span class="hljs-number">0.1150</span>Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">109</span>us/sample - loss: <span class="hljs-number">179892.5998</span> - accuracy: <span class="hljs-number">0.1010</span>Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">107</span>us/sample - loss: <span class="hljs-number">224190.1923</span> - accuracy: <span class="hljs-number">0.1040</span>Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">108</span>us/sample - loss: <span class="hljs-number">258435.1619</span> - accuracy: <span class="hljs-number">0.0920</span>&lt;tensorflow.python.keras.callbacks.History at <span class="hljs-number">0x264cefda748</span>&gt;</code></pre></div><h2 id="2-Functional-Model-函数模型"><a href="#2-Functional-Model-函数模型" class="headerlink" title="(2) Functional Model (函数模型)"></a>(2) Functional Model (函数模型)</h2><ul><li>多输入/多输出模型</li><li>具有共享图层的模型</li><li>具有非顺序数据流的模型</li></ul><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 输入，可以有多个</span>input1 = tf.keras.Input(shape=(<span class="hljs-number">32</span>,))input2 = tf.keras.Input(shape=(<span class="hljs-number">32</span>,))<span class="hljs-comment"># 层，各输入可以经过不同的层</span>x1 = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)(input1)x2 = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)(input2)x = tf.concat((x1, x2), axis=<span class="hljs-number">-1</span>)x = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)(x)<span class="hljs-comment"># 输出</span>pred = layers.Dense(<span class="hljs-number">10</span>)(x)</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 配置模型</span>model = tf.keras.Model(inputs=(input1, input2), outputs=pred)model.compile(    optimizer=tf.keras.optimizers.RMSprop(<span class="hljs-number">0.001</span>),    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),    metrics=[<span class="hljs-string">'accuracy'</span>])<span class="hljs-comment"># 生成数据</span>data1 = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">32</span>))data2 = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">32</span>))labels = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">10</span>))<span class="hljs-comment"># 训练</span>model.fit((data1, data2), labels, epochs=<span class="hljs-number">10</span>, batch_size=<span class="hljs-number">10</span>)</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">Train on <span class="hljs-number">1000</span> samplesEpoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">424</span>us/sample - loss: <span class="hljs-number">30.9891</span> - accuracy: <span class="hljs-number">0.1120</span>Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">140</span>us/sample - loss: <span class="hljs-number">97.7702</span> - accuracy: <span class="hljs-number">0.1050</span>Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">142</span>us/sample - loss: <span class="hljs-number">156.0789</span> - accuracy: <span class="hljs-number">0.0850</span>Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">141</span>us/sample - loss: <span class="hljs-number">88.6646</span> - accuracy: <span class="hljs-number">0.0860</span>Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">143</span>us/sample - loss: <span class="hljs-number">62.6547</span> - accuracy: <span class="hljs-number">0.0960</span>Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">142</span>us/sample - loss: <span class="hljs-number">101.7365</span> - accuracy: <span class="hljs-number">0.0880</span>Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">142</span>us/sample - loss: <span class="hljs-number">145.1425</span> - accuracy: <span class="hljs-number">0.1050</span>Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">143</span>us/sample - loss: <span class="hljs-number">192.7763</span> - accuracy: <span class="hljs-number">0.0840</span>Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">142</span>us/sample - loss: <span class="hljs-number">237.8299</span> - accuracy: <span class="hljs-number">0.1130</span>Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">141</span>us/sample - loss: <span class="hljs-number">310.9853</span> - accuracy: <span class="hljs-number">0.0960</span>&lt;tensorflow.python.keras.callbacks.History at <span class="hljs-number">0x264e2bac248</span>&gt;</code></pre></div><h2 id="3-Subclassing-Model-子类化模型"><a href="#3-Subclassing-Model-子类化模型" class="headerlink" title="(3) Subclassing Model (子类化模型)"></a>(3) Subclassing Model (子类化模型)</h2><p>继承tf.keras.Model，高度可定制化。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 定义模型</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyModel</span><span class="hljs-params">(tf.keras.Model)</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_classes=<span class="hljs-number">10</span>)</span>:</span>        super(MyModel, self).__init__(name=<span class="hljs-string">'my_model'</span>)        self.num_classes = num_classes        <span class="hljs-comment"># 定义模型中的层</span>        self.dense_1 = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)        self.dense_2 = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)        self.dense_3 = layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>)        self.dense_4 = layers.Dense(<span class="hljs-number">10</span>)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span><span class="hljs-params">(self, inputs)</span>:</span>        <span class="hljs-comment"># 使用上面定义的层进行前向传播</span>        x1 = self.dense_1(inputs[<span class="hljs-number">0</span>])        x2 = self.dense_2(inputs[<span class="hljs-number">1</span>])        x = tf.concat((x1, x2), axis=<span class="hljs-number">-1</span>)        x = self.dense_3(x)        <span class="hljs-comment"># 输出</span>        pred = self.dense_4(x)        <span class="hljs-keyword">return</span> pred</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 配置模型</span>model = MyModel(num_classes=<span class="hljs-number">10</span>)model.compile(    optimizer=tf.keras.optimizers.RMSprop(<span class="hljs-number">0.001</span>),    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),    metrics=[<span class="hljs-string">'accuracy'</span>])<span class="hljs-comment"># 生成数据</span>data1 = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">32</span>))data2 = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">32</span>))labels = np.random.random((<span class="hljs-number">1000</span>, <span class="hljs-number">10</span>))<span class="hljs-comment"># 训练</span>model.fit((data1, data2), labels, epochs=<span class="hljs-number">10</span>, batch_size=<span class="hljs-number">10</span>)</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">Train on <span class="hljs-number">1000</span> samplesEpoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">381</span>us/sample - loss: <span class="hljs-number">32.4554</span> - accuracy: <span class="hljs-number">0.1120</span>Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">143</span>us/sample - loss: <span class="hljs-number">111.5987</span> - accuracy: <span class="hljs-number">0.1100</span>Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">138</span>us/sample - loss: <span class="hljs-number">137.5670</span> - accuracy: <span class="hljs-number">0.1070</span>Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">138</span>us/sample - loss: <span class="hljs-number">78.4946</span> - accuracy: <span class="hljs-number">0.1010</span>Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">140</span>us/sample - loss: <span class="hljs-number">54.7856</span> - accuracy: <span class="hljs-number">0.0950</span>Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">151</span>us/sample - loss: <span class="hljs-number">88.2867</span> - accuracy: <span class="hljs-number">0.0980</span>Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">143</span>us/sample - loss: <span class="hljs-number">124.9134</span> - accuracy: <span class="hljs-number">0.0920</span>Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">139</span>us/sample - loss: <span class="hljs-number">168.2450</span> - accuracy: <span class="hljs-number">0.1100</span>Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">138</span>us/sample - loss: <span class="hljs-number">229.4246</span> - accuracy: <span class="hljs-number">0.1130</span>Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span><span class="hljs-number">1000</span>/<span class="hljs-number">1000</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">139</span>us/sample - loss: <span class="hljs-number">273.8532</span> - accuracy: <span class="hljs-number">0.1020</span>&lt;tensorflow.python.keras.callbacks.History at <span class="hljs-number">0x264eba423c8</span>&gt;</code></pre></div><h1 id="4-练习"><a href="#4-练习" class="headerlink" title="4. 练习"></a>4. 练习</h1><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npiris = datasets.load_iris()data = iris.datalabels = iris.targetdata = np.concatenate((data,labels.reshape(<span class="hljs-number">150</span>,<span class="hljs-number">1</span>)),axis=<span class="hljs-number">-1</span>)np.random.shuffle(data)</code></pre></div><div class="hljs"><pre><code class="hljs python">data.shape</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">(<span class="hljs-number">150</span>, <span class="hljs-number">5</span>)</code></pre></div><div class="hljs"><pre><code class="hljs python">X = data[:,:<span class="hljs-number">4</span>]Y = data[:,<span class="hljs-number">-1</span>]print(X.shape, Y.shape)</code></pre></div><div class="hljs"><pre><code class="hljs scheme">(<span class="hljs-name">150</span>, <span class="hljs-number">4</span>) (<span class="hljs-name">150</span>,)</code></pre></div><div class="hljs"><pre><code class="hljs python">print(np.unique(Y))</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">[<span class="hljs-number">0.</span> <span class="hljs-number">1.</span> <span class="hljs-number">2.</span>]</code></pre></div><div class="hljs"><pre><code class="hljs python">print(X[<span class="hljs-number">0</span>])</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">[<span class="hljs-number">6.3</span> <span class="hljs-number">2.7</span> <span class="hljs-number">4.9</span> <span class="hljs-number">1.8</span>]</code></pre></div><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<span class="hljs-keyword">import</span> tensorflow.keras.layers <span class="hljs-keyword">as</span> layers<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyModel</span><span class="hljs-params">(tf.keras.Model)</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_classes=<span class="hljs-number">3</span>)</span>:</span>        super(MyModel, self).__init__()        self.num_classes = num_classes        self.Dense1 = layers.Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">4</span>,))        self.Dense2 = layers.Dense(<span class="hljs-number">3</span>, activation=<span class="hljs-string">'relu'</span>)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span><span class="hljs-params">(self, inputs)</span>:</span>        x = self.Dense1(inputs)        x = self.Dense2(x)        <span class="hljs-keyword">return</span> xmodel = MyModel(num_classes=<span class="hljs-number">3</span>)</code></pre></div><div class="hljs"><pre><code class="hljs python">model.compile(optimizer=tf.keras.optimizers.Adam(),              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])<span class="hljs-comment">#keras</span>model.fit(X, Y, batch_size=<span class="hljs-number">30</span>, epochs=<span class="hljs-number">50</span>, shuffle=<span class="hljs-literal">True</span>)</code></pre></div><div class="hljs"><pre><code class="hljs angelscript">Train on <span class="hljs-number">150</span> samplesEpoch <span class="hljs-number">1</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">951</span>us/sample - loss: <span class="hljs-number">1.1474</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3333</span>Epoch <span class="hljs-number">2</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">1.0366</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3333</span>Epoch <span class="hljs-number">3</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.9883</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5667</span>Epoch <span class="hljs-number">4</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.9546</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5267</span>Epoch <span class="hljs-number">5</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.9236</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3467</span>Epoch <span class="hljs-number">6</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.9083</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5333</span>Epoch <span class="hljs-number">7</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8965</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3600</span>Epoch <span class="hljs-number">8</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8834</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3333</span>Epoch <span class="hljs-number">9</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8712</span> - sparse_categorical_accuracy: <span class="hljs-number">0.3600</span>Epoch <span class="hljs-number">10</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8608</span> - sparse_categorical_accuracy: <span class="hljs-number">0.4467</span>Epoch <span class="hljs-number">11</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8515</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5067</span>Epoch <span class="hljs-number">12</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8443</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5267</span>Epoch <span class="hljs-number">13</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8380</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5533</span>Epoch <span class="hljs-number">14</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.8290</span> - sparse_categorical_accuracy: <span class="hljs-number">0.5800</span>Epoch <span class="hljs-number">15</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.8255</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6400</span>Epoch <span class="hljs-number">16</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.8183</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6467</span>Epoch <span class="hljs-number">17</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.8127</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6267</span>Epoch <span class="hljs-number">18</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.8088</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6467</span>Epoch <span class="hljs-number">19</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.8038</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6600</span>Epoch <span class="hljs-number">20</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">40</span>us/sample - loss: <span class="hljs-number">0.7975</span> - sparse_categorical_accuracy: <span class="hljs-number">0.6733</span>Epoch <span class="hljs-number">21</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7936</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7000</span>Epoch <span class="hljs-number">22</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7882</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7267</span>Epoch <span class="hljs-number">23</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7837</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7600</span>Epoch <span class="hljs-number">24</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.7790</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7533</span>Epoch <span class="hljs-number">25</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7738</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7467</span>Epoch <span class="hljs-number">26</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.7686</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7867</span>Epoch <span class="hljs-number">27</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7659</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7667</span>Epoch <span class="hljs-number">28</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7615</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7867</span>Epoch <span class="hljs-number">29</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7540</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8133</span>Epoch <span class="hljs-number">30</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7510</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8133</span>Epoch <span class="hljs-number">31</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7469</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8067</span>Epoch <span class="hljs-number">32</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7418</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8267</span>Epoch <span class="hljs-number">33</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.7359</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8400</span>Epoch <span class="hljs-number">34</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7317</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8200</span>Epoch <span class="hljs-number">35</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.7242</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8200</span>Epoch <span class="hljs-number">36</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7242</span> - sparse_categorical_accuracy: <span class="hljs-number">0.7933</span>Epoch <span class="hljs-number">37</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7161</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8333</span>Epoch <span class="hljs-number">38</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7104</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8667</span>Epoch <span class="hljs-number">39</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.7069</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8333</span>Epoch <span class="hljs-number">40</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.7032</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8333</span>Epoch <span class="hljs-number">41</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.6971</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8667</span>Epoch <span class="hljs-number">42</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.6927</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8600</span>Epoch <span class="hljs-number">43</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.6875</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8800</span>Epoch <span class="hljs-number">44</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.6831</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8733</span>Epoch <span class="hljs-number">45</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.6797</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8867</span>Epoch <span class="hljs-number">46</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">47</span>us/sample - loss: <span class="hljs-number">0.6758</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8867</span>Epoch <span class="hljs-number">47</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.6699</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8467</span>Epoch <span class="hljs-number">48</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.6677</span> - sparse_categorical_accuracy: <span class="hljs-number">0.8533</span>Epoch <span class="hljs-number">49</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">53</span>us/sample - loss: <span class="hljs-number">0.6607</span> - sparse_categorical_accuracy: <span class="hljs-number">0.9067</span>Epoch <span class="hljs-number">50</span>/<span class="hljs-number">50</span><span class="hljs-number">150</span>/<span class="hljs-number">150</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">60</span>us/sample - loss: <span class="hljs-number">0.6573</span> - sparse_categorical_accuracy: <span class="hljs-number">0.9133</span>&lt;tensorflow.python.keras.callbacks.History at <span class="hljs-number">0x26689c13c88</span>&gt;</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>TensorFlow2学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>TensorFlow</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Change-Font-of-CMD</title>
    <link href="/2020/Change-Font-of-CMD/"/>
    <url>/2020/Change-Font-of-CMD/</url>
    
    <content type="html"><![CDATA[<ol><li><p>安装字体，自己用的是Microsoft Yahei Mono，下载地址 <a href="https://pan.baidu.com/s/1hFn2oYs1lmbDmrZhjJ3QBA&amp;shfl=shareset" target="_blank" rel="noopener">https://pan.baidu.com/s/1hFn2oYs1lmbDmrZhjJ3QBA&amp;shfl=shareset</a> ，提取码: tfgr。</p></li><li><p>打开注册表：win+r输入regedit。</p></li><li><p>定位到计算机 \HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Console\TrueTypeFont ，将936的数值数据修改为*Microsoft Yahei Mono。</p></li><li><p>打开CMD，右键点击打开属性，设置字号等。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Others</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境设置</tag>
      
      <tag>系统设置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Difference Between &#39;+=&#39; and &#39;=+&#39;</title>
    <link href="/2020/Difference-Between-&#39;+=&#39;-and=&#39;=+&#39;/"/>
    <url>/2020/Difference-Between-&#39;+=&#39;-and=&#39;=+&#39;/</url>
    
    <content type="html"><![CDATA[<p>+=运算会在对象原地址之上进行修改，而=…+会新生成一个对象，似乎只继承了值，而没有保留其他属性。</p><p>起因：学习PyTorch时，在一个回归问题的训练过程中更新参数：</p><div class="hljs"><pre><code class="hljs Python"><span class="hljs-comment"># 初始化权重参数</span>w = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dtype=torch.float, requires_grad=<span class="hljs-literal">True</span>)b = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dtype=torch.float, requires_grad=<span class="hljs-literal">True</span>)<span class="hljs-comment"># 学习率</span>lr = <span class="hljs-number">0.001</span>loss = <span class="hljs-number">0</span><span class="hljs-comment"># 训练模型</span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):    <span class="hljs-comment"># 前向传播</span>    y_pred = torch.mm(torch.pow(x, <span class="hljs-number">2</span>), w) + b    <span class="hljs-comment"># 损失函数</span>    loss = torch.pow(y_pred - y, <span class="hljs-number">2</span>) / <span class="hljs-number">2</span>    loss = loss.sum()    <span class="hljs-comment"># 计算梯度</span>    loss.backward()  <span class="hljs-comment"># 梯度存储在grad属性中</span>    <span class="hljs-comment"># 手动更新参数</span>    <span class="hljs-keyword">with</span> torch.no_grad():        w = w - lr * w.grad        b = b - lr * b.grad        <span class="hljs-comment"># 梯度清零</span>        w.grad.zero_()        b.grad.zero_()</code></pre></div><p>报了如下错误：</p><div class="hljs"><pre><code class="hljs Python">AttributeError: <span class="hljs-string">'NoneType'</span> object has no attribute <span class="hljs-string">'zero_'</span></code></pre></div><p>替换为如下后正确了：</p><div class="hljs"><pre><code class="hljs Python">w -= lr * w.gradb -= lr * b.grad</code></pre></div><p>进行测试：</p><div class="hljs"><pre><code class="hljs Python"><span class="hljs-comment"># 初始化权重参数</span>w = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dtype=torch.float, requires_grad=<span class="hljs-literal">True</span>)b = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dtype=torch.float, requires_grad=<span class="hljs-literal">True</span>)print(<span class="hljs-string">'更新前：\nw&#123;&#125;, 梯度&#123;&#125;, 地址&#123;&#125;;  b&#123;&#125;, 梯度&#123;&#125;, 地址&#123;&#125;'</span>.format(w, w.grad, id(w), b, b.grad, id(b)))lr = <span class="hljs-number">0.001</span>y_pred = torch.mm(torch.pow(x, <span class="hljs-number">2</span>), w) + bloss = torch.pow(y_pred - y, <span class="hljs-number">2</span>) / <span class="hljs-number">2</span>loss = loss.sum()loss.backward()<span class="hljs-comment"># 不同方式更新参数</span><span class="hljs-keyword">with</span> torch.no_grad():    w = w - lr * w.grad    b -= lr * b.gradprint(<span class="hljs-string">'更新后：\nw&#123;&#125;, 梯度&#123;&#125;, 地址&#123;&#125;;  b&#123;&#125;, 梯度&#123;&#125;, 地址&#123;&#125;'</span>.format(w, w.grad, id(w), b, b.grad, id(b)))</code></pre></div><p>运行结果：</p><div class="hljs"><pre><code class="hljs Python">更新前：wtensor([[<span class="hljs-number">0.1969</span>]], requires_grad=<span class="hljs-literal">True</span>), 梯度<span class="hljs-literal">None</span>, 地址<span class="hljs-number">1166287893352</span>;  btensor([[<span class="hljs-number">-0.9487</span>]], requires_grad=<span class="hljs-literal">True</span>), 梯度<span class="hljs-literal">None</span>, 地址<span class="hljs-number">1166290443064</span>更新后：wtensor([[<span class="hljs-number">0.3587</span>]]), 梯度<span class="hljs-literal">None</span>, 地址<span class="hljs-number">1166290440344</span>;  btensor([[<span class="hljs-number">-0.5492</span>]], requires_grad=<span class="hljs-literal">True</span>), 梯度tensor([[<span class="hljs-number">-399.5237</span>]]), 地址<span class="hljs-number">1166290443064</span></code></pre></div><p>w的地址发生了改变且没有继承原来的梯度。</p>]]></content>
    
    
    <categories>
      
      <category>Pytorch学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pip tips</title>
    <link href="/2020/pip-tips/"/>
    <url>/2020/pip-tips/</url>
    
    <content type="html"><![CDATA[<h3 id="1-指定源"><a href="#1-指定源" class="headerlink" title="1. 指定源"></a>1. 指定源</h3><p>使用如下方法指定源：</p><div class="hljs"><pre><code class="hljs sql">pip <span class="hljs-keyword">install</span> &lt;<span class="hljs-keyword">package</span>&gt; -i &lt;<span class="hljs-keyword">source</span>&gt;</code></pre></div><p>最常用的国内源是 <a href="https://pypi.tuna.tsinghua.edu.cn/simple/" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple/</a> 清华源。</p><h3 id="2-设置超时时间"><a href="#2-设置超时时间" class="headerlink" title="2. 设置超时时间"></a>2. 设置超时时间</h3><p>使用如下方法设置超时时间（单位为秒）：</p><div class="hljs"><pre><code class="hljs verilog">pip install --<span class="hljs-keyword">default</span>-<span class="hljs-keyword">time</span>=&lt;<span class="hljs-keyword">time</span>&gt; &lt;<span class="hljs-keyword">package</span>&gt;</code></pre></div><h3 id="3-本地安装方法"><a href="#3-本地安装方法" class="headerlink" title="3. 本地安装方法"></a>3. 本地安装方法</h3><p>首先在对应的环境中执行以下代码，可以查看这个环境的pip支持的安装包类型：</p><div class="hljs"><pre><code class="hljs css"><span class="hljs-selector-tag">import</span> <span class="hljs-selector-tag">pip</span><span class="hljs-selector-class">._internal</span><span class="hljs-selector-class">.pep425tags</span><span class="hljs-selector-tag">print</span>(<span class="hljs-selector-tag">pip</span><span class="hljs-selector-class">._internal</span><span class="hljs-selector-class">.pep425tags</span><span class="hljs-selector-class">.get_supported</span>())</code></pre></div><p>然后到 <a href="https://pypi.org/" target="_blank" rel="noopener">https://pypi.org/</a> 或其他源网站，搜索需要的包。</p><ul><li>在 Release history 中可以选择自己需要的版本。</li><li>在 Download files 中可以找到安装包，选择自己的pip支持的类型下载到本地。</li></ul><p>下载完成后，使用pip安装即可。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>pip</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[TF2]1. Installation</title>
    <link href="/2020/1-TF2-Installation/"/>
    <url>/2020/1-TF2-Installation/</url>
    
    <content type="html"><![CDATA[<p>在 <a href="https://tensorflow.google.cn/install/gpu" target="_blank" rel="noopener">https://tensorflow.google.cn/install/gpu</a> 中查看各个依赖软件的版本要求。</p><h4 id="1-安装Nvidia驱动"><a href="#1-安装Nvidia驱动" class="headerlink" title="1. 安装Nvidia驱动"></a><strong>1. 安装Nvidia驱动</strong></h4><p>可以直接在GeForce Experience中更新驱动程序，或在 <a href="https://www.geforce.cn/drivers" target="_blank" rel="noopener">https://www.geforce.cn/drivers</a> 查找与自己显卡相符的驱动程序下载安装。</p><h4 id="2-安装CUDA"><a href="#2-安装CUDA" class="headerlink" title="2. 安装CUDA"></a><strong>2. 安装CUDA</strong></h4><p>进入<a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit</a> ，选择下载，进入选择页面。</p><p>点击Legacy Releases，选择需要的CUDA版本。自己安装的是TensorFlow2.1.0，需要的CUDA版本为10.1。</p><p>进入系统选择页面，选择Windows-x86_64-10，安装方式建议exe(local)，方式因网络问题造成安装失败。</p><p>选择Base Installer中的Download，下载CUDA的本地安装包，安装。默认安装路径为C:\ProgramData\NVIDIA GPU Computing Toolkit。</p><p>安装完成后，在命令行运行<code>nvcc -V</code>查看CUDA版本以验证安装是否成功。</p><h4 id="3-安装CUDNN"><a href="#3-安装CUDNN" class="headerlink" title="3. 安装CUDNN"></a><strong>3. 安装CUDNN</strong></h4><p>进入<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-download</a> ，登录并填写问卷，进入下载页面。选择与CUDA版本相符的CUDNN，这里选择cuDNN v7.6.5 (November 5th, 2019) for CUDA 10.1，<br>cuDNN Library for Windows 10下载。</p><p>下载完成后，解压压缩包，将三个文件夹中的文件分别移动至CUDA安装路径中的对应文件夹里。</p><h4 id="4-安装TensorFlow"><a href="#4-安装TensorFlow" class="headerlink" title="4. 安装TensorFlow"></a><strong>4. 安装TensorFlow</strong></h4><ul><li>网络环境好：</li></ul><p>直接使用<code>pip install tensorflow-gpu==2.1.0</code>即可安装所有依赖库。</p><ul><li><p>网络环境不好，直接使用pip容易失败：</p><p>在 <a href="https://pypi.org/" target="_blank" rel="noopener">https://pypi.org/</a> 直接搜索需要的库，在release history中选择合适版本，下载后进行本地安装<code>pip install [本地路径]</code>。</p><p>查看pip支持的安装包类型，可以在需要安装TensorFlow的python环境中执行：</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pip._internal.pep425tagsprint(pip._internal.pep425tags.get_supported())</code></pre></div></li></ul>]]></content>
    
    
    <categories>
      
      <category>TensorFlow2学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>TensorFlow</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Test Blog</title>
    <link href="/2020/Test-Blog/"/>
    <url>/2020/Test-Blog/</url>
    
    <content type="html"><![CDATA[<h1 id="标题测试"><a href="#标题测试" class="headerlink" title="标题测试"></a>标题测试</h1><h2 id="LaTex"><a href="#LaTex" class="headerlink" title="LaTex"></a>LaTex</h2><ul><li>行内公式$ c = \sqrt{a^{2}+b_{xy}^{2}+e^{x}} $</li><li><p>公式块</p><script type="math/tex; mode=display">c = \sqrt{a^{2}+b_{xy}^{2} +e^{x}}</script><blockquote><p>引用</p></blockquote></li></ul><p><em>粗体</em>   <strong>斜体</strong></p><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><div class="table-container"><table><thead><tr><th>Tables</th><th style="text-align:center">Are</th><th style="text-align:right">Cool</th></tr></thead><tbody><tr><td>col 3 is</td><td style="text-align:center">right-aligned</td><td style="text-align:right">$1600</td></tr><tr><td>col 2 is</td><td style="text-align:center">centered</td><td style="text-align:right">$12</td></tr><tr><td>zebra stripes</td><td style="text-align:center">are neat</td><td style="text-align:right">$1</td></tr></tbody></table></div><h2 id="代码段"><a href="#代码段" class="headerlink" title="代码段"></a>代码段</h2><div class="hljs"><pre><code class="hljs python3">import numpy as np</code></pre></div><h2 id="图片测试"><a href="#图片测试" class="headerlink" title="图片测试"></a>图片测试</h2><ul><li>图片<br><img src="http://ww2.sinaimg.cn/large/6aee7dbbgw1efffa67voyj20ix0ctq3n.jpg" srcset="/img/loading.gif" alt="测试图片"></li><li>图片链接<br><a href="http://ww2.sinaimg.cn/large/6aee7dbbgw1efffa67voyj20ix0ctq3n.jpg" target="_blank" rel="noopener">测试图片</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Others</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Others</tag>
      
      <tag>Blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/hello-world/"/>
    <url>/2020/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><div class="hljs"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="hljs"><pre><code class="hljs bash">$ hexo server</code></pre></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><div class="hljs"><pre><code class="hljs bash">$ hexo generate</code></pre></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><div class="hljs"><pre><code class="hljs bash">$ hexo deploy</code></pre></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
